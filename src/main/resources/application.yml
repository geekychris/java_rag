server:
  port: 8080

spring:
  application:
    name: rag-service
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        model: llama2
      embedding:
        model: llama2

opensearch:
  host: localhost
  port: 30920
  scheme: http
  connection-timeout: 5000
  socket-timeout: 60000

rag:
  default-index-name: documents
  embedding-dimension: 4096
  max-search-results: 10
  summarization:
    enabled: true
    model: llama2
    max-input-tokens: 8000
    max-output-tokens: 1000
    temperature: 0.3
    system-prompt: "You are an AI assistant that provides concise, accurate summaries based on search results and user queries."

logging:
  level:
    com.example.ragservice: DEBUG
    org.opensearch: INFO
    org.springframework.ai: DEBUG

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics
      cors:
        allowed-origins: "http://localhost:3000,http://127.0.0.1:3000"
        allowed-methods: GET,POST,PUT,DELETE,OPTIONS
        allowed-headers: "*"
        allow-credentials: false
        max-age: 3600
  endpoint:
    health:
      show-details: always
